\chapter{Experimental Evaluation}\label{chap:experiments}
This chapter will investigate the~performance of the~\emph{hybrid} approach for integrated synthesis methods extensions \,--\, multi-property and optimal synthesis \,--\, for various case studies and properties.
Moreover,~we will also introduce a~preliminary results of the~performance of the~designed approach for both \emph{parameter} and \emph{combined} synthesis.
Further on,~we demonstrate the~applicability of \toolname{} and interpret the~synthesis results for three of these case studies.
All experiments are run on a~Debian~GNU/Linux~10 machine with Intel(R) Core(TM) i7-3770K (8 cores at 3.50GHz) and using up to 32 GB RAM,~with all the~algorithms being executed single-threaded.

\section{Performance Evaluation of Advanced Methods}
This section aims to demonstrate the~performance of advanced integrated methods for both \textit{multi-property} and \textit{optimal} synthesis on various synthesis problems from different application domains.
In particular,~we compare its performance with the~\emph{one-by-one} enumeration representing the~baseline algorithm implemented in the~existing synthesis tools such as QFLan~\cite{qflan} and ProFeat~\cite{profeat}.
Experiments in previous papers~\cite{cegar,cegis} have shown that the~synthesis methods implemented in these tools have evident deficits on the~investigated benchmarks.
Moreover, experiments in~\cite{roman-DP} have shown that presented hybrid method significantly outperform both state-of-the art synthesis approaches \,--\, CEGIS and AR.
These facts is supported by comparing the~hybrid approach only with the~one-by-one enumeration we present in this section.
For each case study,~we report the~results for \textit{unfeasibility} problems with one property and two properties,~and \textit{optimal} synthesis problem and its \textit{relative} variant with $\varepsilon = 0.05$.
In all cases,~the~synthesis methods have to explore the~whole design space.
The~metrics marks with * represent the~qualified estimates.
We consider the following case studies:

\paragraph{Herman.}
This model represents distributed asynchronous protocol for rings with self-stabilisation~\cite{herman1,herman2}.
The~protocol is extended with a~choice for flipping several unfair coins,~and each station in the~ring includes one-bit memory.
All stations in the~ring have equivalent behaviour,~i.e.,~they are anonymous,~but they decide based on the~own local events and value of the~memory.
The~family maintains this anonymity and describes the~different variations of coin choice and updates of memory.
We are interested mainly in the~expected time until \emph{stabilisation}.
    
\begin{table}[h!]
\centering
\begin{tabular}{l|cccc}
    \hline \hline 
    & \multicolumn{1}{l}{\textbf{1 property}} & \multicolumn{1}{l}{\textbf{2 properties}} & \multicolumn{1}{l}{\textbf{optimal}} & \multicolumn{1}{l}{\textbf{$\mathbf{5\%}$-optimal}} \\ \hline
    \textbf{1-by-1} & 32h & 40h & 32h & \,--\, \\
    \textbf{Hybrid} & 90s & 105s & 21m & 8m \\ \hline \hline
\end{tabular}
\caption{\textbf{Herman}: Family size: $3.1M$, Number of parameters: $7$, Average MC size: $1.1k$.}
\end{table}

\paragraph{DPM.}
It represents a~partial information scheduler for a~disk power manager motivated by~\cite{dpm1}.
This model have been precise described in Section~\ref{sec:dpm}.
We are interested primarily in the~expected energy consumption and expected number of lost requests.

\begin{table}[h!]
\centering
\begin{tabular}{l|cccc}
    \hline \hline 
    & \multicolumn{1}{l}{\textbf{1 property}} & \multicolumn{1}{l}{\textbf{2 properties}} & \multicolumn{1}{l}{\textbf{optimal}} & \multicolumn{1}{l}{\textbf{$\mathbf{5\%}$-optimal}} \\ \hline
    \textbf{1-by-1} & 31d & 35d & 31d & \,--\, \\
    \textbf{Hybrid} & 72m & 84m & 9.7h & 6.2h \\ \hline \hline
\end{tabular}
\caption{\textbf{DPM}:  Family size: $43M$, Number of parameters: $16$, Average MC size: $3.6k$.}
\end{table}

\paragraph{Maze.}
It represents a planning problem typically modelled as POMDP~\cite{maze}.
The~family includes all deterministic strategies which are based on observation,~and containing small memory with a~fixed upper bound.
We are interested primarily in the~expected time to the \emph{goal}.

\begin{table}[h!]
\centering
\begin{tabular}{l|cccc}
    \hline \hline 
    & \multicolumn{1}{l}{\textbf{1 property}} & \multicolumn{1}{l}{\textbf{2 properties}} & \multicolumn{1}{l}{\textbf{optimal}} & \multicolumn{1}{l}{\textbf{$\mathbf{5\%}$-optimal}} \\ \hline
    \textbf{1-by-1} & 25h & 31h & 25h & \,--\, \\
    \textbf{Hybrid} & 63m & 65m & 78m & 59m \\ \hline \hline
\end{tabular}
\caption{\textbf{Maze}:  Family size: $9.4M$, Number of parameters: $22$, Average MC size: $0.2k$.}
\end{table}

\paragraph{Pole.}
It models balancing a pole in an unknown and noisy environment~\cite{pole}.
A~model controller optimises an~expected behaviour during the deployment without dependence on the~current (hidden) environment since it is preferred before the~finite set of environment behaviours.
The~family described schedulers that are independent of hidden information.
We are interested mainly in the~expected time until \emph{failure}.

\begin{table}[h!]
\centering
\begin{tabular}{l|cccc}
    \hline \hline 
    & \multicolumn{1}{l}{\textbf{1 property}} & \multicolumn{1}{l}{\textbf{2 properties}} & \multicolumn{1}{l}{\textbf{optimal}} & \multicolumn{1}{l}{\textbf{$\mathbf{5\%}$-optimal}} \\ \hline
    \textbf{1-by-1} & 23h & 30h & 23h & \,--\, \\
    \textbf{Hybrid} & 7s & 8s & 11m & 60s \\ \hline \hline
\end{tabular}
\caption{\textbf{Pole}:  Family size: $1.3M$, Number of parameters: $17$, Average MC size: $5.6k$.}
\end{table}

\paragraph{Grid.}
It represents a~model describing again partially observable MDPs (POMDPs)~\cite{pomdp1}.
There is an~agent who tries to locate a~target cell in a~4x4 grid.
We are interested in lower- and upper- bounded properties on the~expected number of steps.

\begin{table}[h!]
\centering
\begin{tabular}{l|cccc}
    \hline \hline 
    & \multicolumn{1}{l}{\textbf{1 property}} & \multicolumn{1}{l}{\textbf{2 properties}} & \multicolumn{1}{l}{\textbf{optimal}} & \multicolumn{1}{l}{\textbf{$\mathbf{5\%}$-optimal}} \\ \hline
    \textbf{1-by-1} & 16m & 19m & 16m & \,--\, \\
    \textbf{Hybrid} & 31s & 35s & 47s & 9s \\ \hline \hline
\end{tabular}
\caption{\textbf{Grid}: Family size: $65k$, Number of parameters: $8$, Average MC size: $1.2k$.}
\end{table}
    

\paragraph{Evaluation.}
As we have already said,~we are based on what has already been shown in previous articles~\cite{roman-DP,cegar,cegis}.
As a~basis,~we know that a~hybrid oracle is orders of magnitude faster than one-by-one enumeration when analysing single property.
Based on the~results obtained in the~framework of all considered case studies,~we can draw the~following conclusions,~which confirm the~tables above.
An~integrated \emph{multi-property} synthesis slows down both approaches,~although the~hybrid slowdown is almost negligible.
An~\emph{optimal} synthesis slows down only the~hybrid approach,~yet it is still incomparably faster than naive one-by-one enumeration.
Moreover,~a~hybrid oracle supports $\varepsilon$-optimal synthesis,~which is even faster.

% \paragraph{\toolname{} scalability.}

% \begin{table}[h!]
% \centering
% \begin{tabular} {l|c|c|c|c|c|c}
% {\multirow{2}{*}{model}} & 1-by-1 & CEGIS & \multicolumn{2}{c|}{AR} & \multicolumn{2}{c}{\textbf{hybrid}} \\
% & time & time & iters & time & (CEGIS,AR) iters & time \\
% \hline
% {\emph{Herman-5k}} & 1m & \textcolor{red}{$\geq$24h} & 531 & \textcolor{red}{3m} & (571, 7) & \textbf{12s} \\ \hline
% {\emph{Herman-3M}} & 27h & \textcolor{red}{$\geq$48h} & 83k & \textcolor{red}{55h} & (16197, 3) & \textbf{17m} \\ \hline
% \end{tabular}
% \caption{Efficiency of synthesis methods for synthesising optimal \emph{Herman's stabilisation algorithm}.} 
% \end{table}


\section{Performance Evaluation of Combined Synthesis}
This section aims to demonstrate the~performance of the~designed and implemented method for combined probabilistic synthesis.
We remind that this synthesis problem included both kinds of parameters,~those that affect the~topology of MCs and those that affect the~transition probabilities of MCs.
We only present the~results achieved by our tool \toolname{},~as there is no other tool that would support this combined synthesis of probabilistic programs.
For each considered case study,~we report the~results for \textit{optimal synthesis} and its \textit{relative} variant with $\varepsilon = 0.05$,~as in the~previous section.
Such a~task representing the~optimal synthesis is the~most advanced and,~therefore,~most suitable for measuring the~performance of the~designed method because it has to explore the~whole design space.
We consider the~following case studies:

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
$\lvert \mathbf{K} \rvert$ & $\lvert \mathbf{V} \rvert$ & $\lvert \varPhi \rvert$ & $\lvert \mathcal{\mathbf{F}} \rvert$ & $\overline{\mathbf{\lvert MC \rvert}}$ & $\mathbf{\varepsilon = 0.0}$ & $\mathbf{\varepsilon = 0.05}$ \\ \hline
4 & 2 & 7 & $4k \times 2 \cdot \lvert 0.50 \rvert$ & 13 & 8m & 50s \\ \hline
\end{tabular}
\caption{\textbf{Knuth-Yao Die:} Performance evaluation of combined probabilistic synthesis.}
\end{table}

\paragraph{Knuth \& Yao Die.}
This case study considers a~probabilistic program modelling a~fair dice using only fair coins.
The program starts at the~initial state $s_0$ and repeatedly tosses a~coin.
Whenever tail appears,~it takes the~one branch,~and when headers appear,~another branch,~and in this way it branching own state tree (see Figure~\ref{fig:kydie}).
This continues until the~value of the~dice is decided.
We consider six specifications representing the~probability of reaching a~final state $s_7$ (depicted as blue in Figure~\ref{fig:kydie}) with a~specific dice value to prove that the~program is correct.
Further,~we minimise the~expected number of coin tosses to obtain the~specific dice value.
We consider a~sketch with four parameters affecting the~model topology (depicted as \circled{?} in Figure~\ref{fig:kydie}(a)) that have simultaneously undefined transition probabilities $p_0$ and $p_1$.
Since each parameter affecting topology can represent arbitrary model state $s_0, \dots, s_7$,~we obtain the~sketch describing of $8^4 = 4096$ various pMCs.
The~probability parameters $p_0$ and $p_1$ are defined over the~interval $[0.0, 0.5]$ since they cover the~transitions asymmetrically.
\toolname{} synthesised an~optimal solution depicted in Figure~\ref{fig:kydie}(b) in $8$ minutes with $\varepsilon = 0.0$ and $50$ seconds when computes with $\varepsilon = 0.05$. 
We have found that the~minimum expected number of coin tosses is $\frac{11}{3}$.
The~synthesised strategy chooses for the~searched states always states $s_3, \dots, s_6$ in arbitrary order,~and the~transition probabilities representing the~fair coin (${\approx} \, 0.5$).
We emphasise that with this case study,~we have also verified the~correctness of our implementation,~as a~result corresponds to what is expected.

\begin{figure*}[h!]
\centering
\includegraphics[width=1.0\textwidth]{figures/kydie.pdf}
\caption{Models represent the state space of the program for the Knuth \& Yao case study.}%
\label{fig:kydie}%
\end{figure*}

\paragraph{NAND multiplexing.}
This case study concerns NAND multiplexing,~a technique for constructing reliable computation from unreliable devices.
It describes fault-tolerant hardware by having copies of a~NAND unit all doing the~same work~\cite{nand}.
In the considered model,~we assumed that the~inputs $X$ and $Y$ are identically distributed (with probability $prob1$ of being stimulated),~and the~NAND gates suffer from a~von Neumann fault (inverted output) with probability $perr$.
We verify one optimal target describing that the~system will reach the~target state,~and the~resulting value of gate will be correct.
Parameters are the~probabilities of the~faultiness of the~units ($prob1$) and the~probabilities of erroneous inputs ($perr$).
The intervals for these parameters are taken from the following paper~\cite{nand}.
We consider instance $(20, 13)$,~where $N=20$ represents the~number of inputs in each bundle and $K=13$ the~number of restorative stages.
We chose such an~instance to get large MCs,~as the~considered family contains two probability parameters,~and thus we obtained case study with different properties.

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
$\lvert \mathbf{K} \rvert$ & $\lvert \mathbf{V} \rvert$ & $\lvert \varPhi \rvert$ & $\lvert \mathcal{\mathbf{F}} \rvert$ & $\overline{\mathbf{\lvert MC \rvert}}$ & $\mathbf{\varepsilon = \todo{?}}$ & $\mathbf{\varepsilon = 0.15}$ \\ \hline
0 & 2 & 1 & $2 \cdot \lvert 0.12 \rvert$ & 1M & \todo{?} & 1h \\ \hline
\end{tabular}
\caption{\textbf{NAND multiplexing:} Performance evaluation of combined probabilistic synthesis.}
\end{table}

\paragraph{DPM.}
This case study has been precisely introduced in Section~\ref{sec:dpm}.
We consider the~domains parameters representing queue capacity,~four power profiles and three thresholds,~and two probabilistic parameters representing time resolutions.
Analysed family describes $16k$ parametric candidates that including two parameters with an~interval length of $0.2$.
We are interested in the~expected power consumption and expected number of lost requests.

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
$\lvert \mathbf{K} \rvert$ & $\lvert \mathbf{V} \rvert$ & $\lvert \varPhi \rvert$ & $\lvert \mathcal{\mathbf{F}} \rvert$ & $\overline{\mathbf{\lvert MC \rvert}}$ & $\mathbf{\varepsilon = 0.0}$ & $\mathbf{\varepsilon = 0.05}$ \\ \hline
7 & 2 & 2 & $16k \times 2 \cdot \lvert 0.20 \rvert$ & 400 & 2.8h & 2.1h \\ \hline
\end{tabular}
\caption{\textbf{DPM:} Performance evaluation of combined probabilistic synthesis.}
\end{table}

\paragraph{Herman.}
This case study will be in more detail introduced and described in Section~\ref{sec:herman}.
Domains parameters represent the memory updates, and the probability parameters represent different coin biases based on the variable and memory value.
The~synthesis target is to identify the~protocol version that minimises stabilisation time.

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
$\lvert \mathbf{K} \rvert$ & $\lvert \mathbf{V} \rvert$ & $\lvert \varPhi \rvert$ & $\lvert \mathcal{\mathbf{F}} \rvert$ & $\overline{\mathbf{\lvert MC \rvert}}$ & $\mathbf{\varepsilon = 0.0}$ & $\mathbf{\varepsilon = 0.05}$ \\ \hline
3 & 4 & 1 & $8 \times 4 \cdot \lvert 0.25 \rvert$ & 1.5k & \todo{?} & 52m \\ \hline
\end{tabular}
\caption{\textbf{Herman:} Performance evaluation of combined probabilistic synthesis.}
\end{table}

\section{Applicability}

\subsection{Maze} 
This synthesis problem considers an~instance of POMDP synthesis of the~controller.
Figure~\ref{fig:maze} depicts a~\emph{maze} in which operates an~agent starting at a~random location.
The~agent has simple sensor detecting walls,~but it cannot recognise cells within the~maze that have walls at identical directions \,--\,~e.g. cells $5$ and $10$,~or $1$ and $3$.
We denote such cells as observation-equivalent,~and they are depicted in Figure~\ref{fig:maze} by the~same colour.
The~agent performs the~actions representing the~movements in the~four available directions corresponds to the~cardinals.
However,~these movements are performed with some level of non-determinism,~i.e.,~they are subject to a~random error.
For instance,~when the~agent wants to move to the~west,~there is a~small probability that it will move to the~east.

We design a sketch for the~agent's controller that helps it reach the target cell representing the~maze's exit \,--\, cell 12.
The~controller has one bit of memory available which is initially set to value $0$.
The~holes in this sketch represent the~available actions concerning the~current observation.
The~direction for steering and setting a~new value of the~memory represents actions,~and observation is represented by the~current memory value and detected walls in the~current cell.
This sketch describes a family with $9.4M$ various programs.
Our target is to synthesise a~program that minimises the~expected number of steps to achieve the~maze's exit.

\toolname{} explores the set of candidate programs in $one$ hour,~whereas the~naive one-by-one enumeration takes more than one day.
Figure~\ref{fig:maze} depicts the synthesised strategy of the selected controller,~which is optimal given the~expected number of steps to reach the~exit.
Arrows depict the~direction of steering concerning the~current memory value (number at the~start of an~arrow) and the~corresponding memory update (number at the~end of an~arrow).
For instance,~when an~agent is currently in cell $3$,~it moves to the~east when the~memory value is equal to $0$ and moves to the~west when the~memory contains 0,~while the~value of the~memory remains unchanged in both cases.

\begin{figure}[h!]
\centering
\includegraphics[width=0.4\textwidth]{figures/maze.pdf}
\caption{The state-space of the~\textit{Maze} model with a~marked target state and the~observation groups. A~right side represents the~found optimal strategy to reach the~target location within the~minimal expected time. The~initial state is selected randomly with a~memory value of 0.}%
\label{fig:maze}%
\end{figure}

When an~agent is in the~cell with enclosing walls (cells 0,~2 and 4),~it can navigate to the~exit since it knows its current position within the~maze.
Likewise,~when the~agent navigates from cells $11$ or $13$,~it selects always to the~north to reach cells $0$ or $4$ eventually.
Otherwise,~when the~agent is located in purple or orange cells,~it must first determine its current position within the~maze by moving in one direction.
For instance,~the~agent deployed at cell $1$ or $3$ moves first to the~west (recall that the~memory is initially set to 0),~where it reaches the~cell to determine the~current position.
Similarly,~when the~agent deployed at cell $5$-$10$,~it moves to the~north.
In this observation group,~it is indeed more beneficial to move to the~north since the~robot is twice as likely to be deployed when starting at locations 5/7/8/10 compared to locations 6 and 9.

The~synthesised expected time to reach the~maze's exit for obtained strategy is ${\approx} \, 9.80$ steps. 
We note that this result cannot be improved by adding more bits to the~controller's memory.

\subsection{Herman} \label{sec:herman}
This model represents a~unidirectional token ring containing an~odd number of connected processes.
Each process has a~Boolean variable and access to its neighbour's variables.
We say that a~process holds a~token if the~value of its variable is equal to the~neighbour.
When only one token remains in the~ring,~such a~situation is denoted a~stable one,~and all other situations are denoted as unstable.
When the~token ring passes from an~unstable to stable configuration,~we say a~protocol is self-stabilising.
An~expected number of rounds to reach a~stable configuration represents a~stabilisation time,~considered a~performance metric.

\begin{figure}[h!]
\centering
\includegraphics[width=1.0\textwidth]{figures/herman_coins.pdf}
\caption{A~round of Herman's protocol with nine processes within ring,~where three processes holds a~token in the~current configuration.}%
\label{fig:herman}%
\end{figure}

We consider a version of \textit{Herman's randomised self-stabilisation protocol}~\cite{herman1,herman2}.
All processes behave the~same in this protocol,~and therefore a~stabilisation cannot be solved in a~deterministic way in such anonymous networks.
This protocol is synchronised,~and in each round,~a~process that does not hold token flips the~value of its variable (see Figure~\ref{fig:herman}(b)).
On the~contrary,~each process that has a~token must decide whether to pass it or not and,~according to this decision,~set the~value of its variable.
A~token disappears from the~circle if two tokens collide in one process.
The original version of the~protocol resolves this decision by a~single biased coin flip.
Figure~\ref{fig:herman}(c) illustrates a~situation when processes $1$ and $5$ remain the~same value of their variable (they keep the~token) and process $7$ decided to flip the~value of its variable (it pass the~token).
However,~we are interested in the~synthesis of alternatives.

We give each station an~additional single bit of memory and the~choice between multiple different coin biases.
We consider a~sketch of this protocol where the~holes represent the~choices of a~coin based on the~memory value and memory updates.
Subsequently,~we obtain the~same protocol for each process by resolving the~individual choices.
The~synthesiser aims to identify the~protocol version that minimises stabilisation time from an~initial configuration,~where each process has a~variable set to true.
We consider a~set of parameters to describe a~family of $3.1M$ candidate programs.

\toolname{} synthesised the~optimal protocol in around $18$ minutes,~while the~naive one-by-one enumeration takes more than one day when we consider a~sketch containing a~system with five processes.
The~synthesised optimal strategy uses the~fairest coins (bias ${\approx} \, 0.25$) and maintains the~values of memory set at true,~when starting from the~initial configuration.
Whenever a~process eventually decides to keep the~token,~the memory is reset to $0$,~and the~process starts using highly unfair coins (bias ${\approx} \, 0.07$). 
Thus,~the~process is more likely to keep its token for a long time until it eventually passed it further.
The~system can,~on average,~stabilise in four rounds when using this synthesised strategy.

\paragraph{Combined Synthesis.}
Up to now,~we presented the~\textit{topology} synthesis.
Its constraints cause the~sketch to contain four parameters with 25 values representing different coin biases combined variable and memory value.
When we refine this topology synthesis by considering $250$ coin biases from the~same interval $[0.0, 0.25]$,~the synthesis problem is intractable as the~family size increases about the~factor $10k$.
Therefore,~we consider an~alternative formulation of the~synthesis problem where we replace these discrete options with continuous transition parameters over the~same interval.
The~combined synthesis method requires around $53$ minutes and guarantees the optimal solution over the~continuous parameters space compared to the~first version,~where were considered only discrete steps.

% Figure~\ref{fig:herman} depicts one round of Herman's protocol.
